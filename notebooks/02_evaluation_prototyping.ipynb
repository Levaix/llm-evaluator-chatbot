{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Prototyping\n",
    "\n",
    "This notebook prototypes and tests the `evaluate_answer` function with various sample student answers.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "We test the evaluation system with:\n",
    "- **Good answers**: Comprehensive, correct responses\n",
    "- **Mediocre answers**: Partially correct with some gaps\n",
    "- **Bad answers**: Incorrect or missing key concepts\n",
    "\n",
    "This helps us understand how well the LLM evaluator performs and identify potential improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from .env file\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file (if it exists)\n",
    "# This allows notebooks to use the same configuration as the main app\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  # Loads variables from .env file in project root\n",
    "    print(\"Environment variables loaded from .env file\")\n",
    "except ImportError:\n",
    "    print(\"python-dotenv not installed. Using system environment variables only.\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not load .env file: {e}\")\n",
    "    print(\"Using system environment variables only.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully\n",
      "Current working directory: c:\\Users\\Levin\\OneDrive\\Desktop\\DAI Assignment Part 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Find project root by looking for src/ directory\n",
    "current = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "# Check if we're in notebooks/ directory\n",
    "if current.name == 'notebooks':\n",
    "    project_root = current.parent\n",
    "else:\n",
    "    # Walk up the directory tree looking for src/ folder\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / 'src').exists() and (parent / 'src' / '__init__.py').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "    \n",
    "    # Fallback: assume current directory is project root if src/ exists here\n",
    "    if project_root is None and (current / 'src').exists():\n",
    "        project_root = current\n",
    "\n",
    "# If still not found, use current directory's parent\n",
    "if project_root is None:\n",
    "    project_root = current.parent if current.name == 'notebooks' else current\n",
    "\n",
    "# Change to project root directory so relative paths work correctly\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Add project root to path to import src modules\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data_loader import load_qa_dataset, get_random_question\n",
    "from src.evaluator import evaluate_answer\n",
    "from src import config\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Modules imported successfully\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data_loader:Successfully loaded 150 question-answer pairs from c:\\Users\\Levin\\OneDrive\\Desktop\\DAI Assignment Part 2\\data\\Q&A_db_practice.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Question:\n",
      "ID: 44\n",
      "Question: Epoch\n",
      "\n",
      "Reference Answer:\n",
      "An epoch is a training iteration that constitutes a complete forward and backward pass through the entire labeled dataset, updating model parameters once per batch, and is repeated until convergence criteria are met\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and pick a sample question\n",
    "# Use absolute path to ensure it works regardless of working directory\n",
    "data_file = project_root / \"data\" / \"Q&A_db_practice.json\"\n",
    "df = load_qa_dataset(path=data_file)\n",
    "sample_q = get_random_question(df)\n",
    "\n",
    "print(\"Sample Question:\")\n",
    "print(f\"ID: {sample_q['id']}\")\n",
    "print(f\"Question: {sample_q['question']}\")\n",
    "print(f\"\\nReference Answer:\\n{sample_q['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case 1: Good Answer\n",
    "\n",
    "A comprehensive, correct answer that covers all key points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.evaluator:Evaluating answer for question ID: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Answer (Good):\n",
      "An epoch is a training iteration that constitutes a complete forward and backward pass through the entire labeled dataset, updating model parameters once per batch, and is repeated until convergence criteria are met\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.llm_interface:Initialized OpenAI client\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:src.evaluator:Parsed LLM score: 100/100\n",
      "INFO:src.evaluator:Loading ROUGE metric...\n",
      "INFO:src.evaluator:ROUGE metric loaded\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:src.evaluator:ROUGE-1: 1.000, ROUGE-L: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Score: 100/100\n",
      "ROUGE-1: 1.000\n",
      "ROUGE-L: 1.000\n",
      "\n",
      "Explanation:\n",
      "**Step 1 - Content Analysis:**\n",
      "The reference answer includes the following key concepts:\n",
      "- Definition of an epoch as a training iteration\n",
      "- Description of a complete forward and backward pass through the entire labeled dataset\n",
      "- Mention of updating model parameters once per batch\n",
      "- Indication that this process is repeated until convergence criteria are met\n",
      "\n",
      "The student's answer contains all these concepts exactly as presented in the reference answer.\n",
      "\n",
      "**Step 2 - Correctness Assessment:**\n",
      "- Correct Elements: \n",
      "  - The definition of an epoch as a training iteration\n",
      "  - The description of a complete forward and backward pass through the entire labeled dataset\n",
      "  - The updating of model parameters once per batch\n",
      "  - The repetition of this process until convergence criteria are met\n",
      "\n",
      "- Missing Elements: None; the student included all relevant concepts.\n",
      "\n",
      "- Errors/Misconceptions: None; the student's answer is accurate.\n",
      "\n",
      "**Step 3 - Semantic Equivalence:**\n",
      "The student's phrasing matches the reference answer exactly, conveying the same meaning without any variation. There are no differences in interpretation or understanding.\n",
      "\n",
      "**Step 4 - Completeness:**\n",
      "The student comprehensively addressed the question by including all critical components of the definition of an epoch. There are no omissions or gaps in the explanation.\n",
      "\n",
      "**Step 5 - Score Justification:**\n",
      "Given that the student's answer is identical to the reference answer, it demonstrates a comprehensive and accurate understanding of the concept of an epoch in machine learning. The answer covers all key concepts without any errors or omissions. Therefore, it aligns with the criteria for an \"Excellent\" score.\n",
      "\n",
      "**Explanation:**\n",
      "You have provided an excellent answer that accurately defines what an epoch is in the context of machine learning. You included all the necessary components, such as the complete forward and backward pass through the dataset and the updating of model parameters. There were no gaps or errors in your response, which shows a strong understanding of the concept. Keep up the great work!\n",
      "\n",
      "**Score:** 100\n"
     ]
    }
   ],
   "source": [
    "# Good answer (comprehensive and correct)\n",
    "good_answer = sample_q['answer']  # Using reference as a \"good\" answer for testing\n",
    "\n",
    "print(\"Student Answer (Good):\")\n",
    "print(good_answer)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Evaluate\n",
    "result_good = evaluate_answer(\n",
    "    question_id=sample_q['id'],\n",
    "    question=sample_q['question'],\n",
    "    reference_answer=sample_q['answer'],\n",
    "    student_answer=good_answer,\n",
    "    language=\"English\"\n",
    ")\n",
    "\n",
    "print(f\"\\nLLM Score: {result_good.llm_score}/100\")\n",
    "print(f\"ROUGE-1: {result_good.rouge_1:.3f}\")\n",
    "print(f\"ROUGE-L: {result_good.rouge_l:.3f}\")\n",
    "print(f\"\\nExplanation:\\n{result_good.llm_explanation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case 2: Mediocre Answer\n",
    "\n",
    "A partially correct answer with some gaps or minor inaccuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.evaluator:Evaluating answer for question ID: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Answer (Mediocre):\n",
      "This is a concept in machine learning. It's used for training models and helps with optimization.\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:src.evaluator:Parsed LLM score: 40/100\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:src.evaluator:ROUGE-1: 0.160, ROUGE-L: 0.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Score: 40/100\n",
      "ROUGE-1: 0.160\n",
      "ROUGE-L: 0.160\n",
      "\n",
      "Explanation:\n",
      "**Step 1 - Content Analysis:**\n",
      "The reference answer defines an epoch as a complete training iteration that includes both a forward and backward pass through the entire dataset, emphasizing the updating of model parameters per batch and the repetition until convergence. The student's answer acknowledges that an epoch is a concept in machine learning related to training models and optimization, but it lacks the specific details about what constitutes an epoch.\n",
      "\n",
      "**Step 2 - Correctness Assessment:**\n",
      "- Correct Elements: The student correctly identifies that an epoch is related to training models in machine learning and mentions its role in optimization.\n",
      "- Missing Elements: The student does not mention the complete forward and backward pass through the dataset, the updating of model parameters, or the concept of convergence criteria.\n",
      "- Errors/Misconceptions: There are no outright errors in the student's answer, but it is overly vague and lacks critical details.\n",
      "\n",
      "**Step 3 - Semantic Equivalence:**\n",
      "While the student's phrasing conveys a general understanding that epochs are related to training and optimization, it does not capture the specific mechanics of what an epoch entails. Therefore, the semantic equivalence is limited; the studentâ€™s answer is too broad and lacks the necessary detail to fully convey the meaning of an epoch.\n",
      "\n",
      "**Step 4 - Completeness:**\n",
      "The student's answer is incomplete. It touches on the concept of epochs but does not provide a comprehensive explanation. Key components such as the forward and backward pass, parameter updates, and convergence criteria are missing, which are essential for a full understanding of the term.\n",
      "\n",
      "**Step 5 - Score Justification:**\n",
      "Based on the rubric, the student's answer demonstrates some understanding of the concept but is significantly lacking in detail and completeness. It falls into the \"31-50 (Insufficient)\" category as it is partially correct but misses most key concepts and contains significant gaps.\n",
      "\n",
      "**Explanation:**\n",
      "You have correctly identified that an epoch is a concept in machine learning related to training models and optimization, which shows a basic understanding. However, your answer lacks critical details that define what an epoch actually involves, such as the complete forward and backward pass through the dataset and the updating of model parameters. To improve, focus on including these essential components in your explanations. Understanding the mechanics of how epochs function in the training process is crucial for a deeper grasp of machine learning concepts.\n",
      "\n",
      "**Score:** 40\n"
     ]
    }
   ],
   "source": [
    "# Mediocre answer (partially correct)\n",
    "mediocre_answer = \"This is a concept in machine learning. It's used for training models and helps with optimization.\"\n",
    "\n",
    "print(\"Student Answer (Mediocre):\")\n",
    "print(mediocre_answer)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Evaluate\n",
    "result_mediocre = evaluate_answer(\n",
    "    question_id=sample_q['id'],\n",
    "    question=sample_q['question'],\n",
    "    reference_answer=sample_q['answer'],\n",
    "    student_answer=mediocre_answer,\n",
    "    language=\"English\"\n",
    ")\n",
    "\n",
    "print(f\"\\nLLM Score: {result_mediocre.llm_score}/100\")\n",
    "print(f\"ROUGE-1: {result_mediocre.rouge_1:.3f}\")\n",
    "print(f\"ROUGE-L: {result_mediocre.rouge_l:.3f}\")\n",
    "print(f\"\\nExplanation:\\n{result_mediocre.llm_explanation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case 3: Bad Answer\n",
    "\n",
    "An incorrect answer or one that misses key concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.evaluator:Evaluating answer for question ID: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Answer (Bad):\n",
      "I don't really know much about this topic. Maybe it's related to data science?\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:src.evaluator:Parsed LLM score: 10/100\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:src.evaluator:ROUGE-1: 0.000, ROUGE-L: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Score: 10/100\n",
      "ROUGE-1: 0.000\n",
      "ROUGE-L: 0.000\n",
      "\n",
      "Explanation:\n",
      "**Step 1 - Content Analysis:**\n",
      "The reference answer defines an epoch in the context of machine learning as a complete training iteration that includes a forward and backward pass through the entire labeled dataset, updating model parameters once per batch, and repeating until convergence criteria are met. The student's answer does not contain any of these key concepts and instead expresses uncertainty about the topic, suggesting a lack of understanding.\n",
      "\n",
      "**Step 2 - Correctness Assessment:**\n",
      "- Correct Elements: None identified; the student did not provide any accurate definitions or explanations related to the concept of an epoch.\n",
      "- Missing Elements: The entire definition of an epoch, including the concepts of forward and backward passes, updating model parameters, and convergence criteria.\n",
      "- Errors/Misconceptions: The statement \"I don't really know much about this topic\" indicates a lack of understanding rather than a misconception, but it does not provide any relevant information about epochs.\n",
      "\n",
      "**Step 3 - Semantic Equivalence:**\n",
      "The student's phrasing does not convey any equivalent meaning to the reference answer. The response does not demonstrate any understanding of the concept of an epoch in machine learning, which is a fundamental aspect of the training process.\n",
      "\n",
      "**Step 4 - Completeness:**\n",
      "The student's response is incomplete as it does not address the question at all. There are no relevant details or explanations provided, and the answer does not reflect any understanding of the topic.\n",
      "\n",
      "**Step 5 - Score Justification:**\n",
      "Based on the rubric, the student's response falls into the \"0-30 (Failing)\" category. There are major misconceptions due to the lack of any relevant content or understanding of the concept of an epoch. The response does not identify any valid concepts, and the overall understanding is fundamentally incorrect.\n",
      "\n",
      "**Explanation:**\n",
      "The student did not demonstrate any understanding of the concept of an epoch in machine learning. An epoch is a critical term that refers to a complete cycle of training through the entire dataset, which includes both forward and backward passes for updating model parameters. To improve, I recommend studying the basics of machine learning training processes, focusing on terms like epochs, iterations, and convergence. Engaging with resources that explain these concepts in detail will help build a foundational understanding.\n",
      "\n",
      "**Score:** 10\n"
     ]
    }
   ],
   "source": [
    "# Bad answer (incorrect or missing key points)\n",
    "bad_answer = \"I don't really know much about this topic. Maybe it's related to data science?\"\n",
    "\n",
    "print(\"Student Answer (Bad):\")\n",
    "print(bad_answer)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Evaluate\n",
    "result_bad = evaluate_answer(\n",
    "    question_id=sample_q['id'],\n",
    "    question=sample_q['question'],\n",
    "    reference_answer=sample_q['answer'],\n",
    "    student_answer=bad_answer,\n",
    "    language=\"English\"\n",
    ")\n",
    "\n",
    "print(f\"\\nLLM Score: {result_bad.llm_score}/100\")\n",
    "print(f\"ROUGE-1: {result_bad.rouge_1:.3f}\")\n",
    "print(f\"ROUGE-L: {result_bad.rouge_l:.3f}\")\n",
    "print(f\"\\nExplanation:\\n{result_bad.llm_explanation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Observations\n",
    "\n",
    "### Strengths of the Evaluation Approach\n",
    "\n",
    "1. **LLM Explanation**: Provides detailed, contextual feedback that goes beyond simple metrics\n",
    "2. **ROUGE Metrics**: Offers objective, quantitative measures of overlap\n",
    "3. **Combined Approach**: LLM + metrics provides both qualitative and quantitative assessment\n",
    "\n",
    "### Potential Improvements\n",
    "\n",
    "1. **Score Parsing**: The score parsing could be more robust (consider structured output formats)\n",
    "2. **Consistency**: LLM scores may vary slightly between runs (temperature=0.2 helps)\n",
    "3. **Fine-tuning**: A fine-tuned model specifically for evaluation could improve consistency\n",
    "4. **Judge LLM**: Using a separate, specialized \"judge\" model could improve evaluation quality\n",
    "5. **Multi-aspect Scoring**: Break down scores by different aspects (accuracy, completeness, clarity)\n",
    "\n",
    "### Alternative Approaches\n",
    "\n",
    "- **Pure Metric-based**: Use only ROUGE/BLEU (fast but less nuanced)\n",
    "- **Fine-tuned Evaluator**: Train a model specifically for answer evaluation\n",
    "- **RLHF**: Use reinforcement learning from human feedback to improve the evaluator\n",
    "- **Ensemble**: Combine multiple LLMs or evaluation methods for robustness\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
